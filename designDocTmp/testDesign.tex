\documentclass{scrreprt}

\usepackage{xcolor} % for different colour comments
\usepackage{tabto}
\usepackage{mdframed}
\mdfsetup{nobreak=true}
\usepackage{xkeyval}
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=red,
    urlcolor=blue
}
\usepackage[skip=2pt, labelfont=bf]{caption}
\usepackage{titlesec}
\usepackage{graphicx}
\usepackage[section]{placeins}
\graphicspath{ {image/} }

\titleformat{\paragraph}
{\normalfont\normalsize\bfseries}{\theparagraph}{1em}{}
\titlespacing*{\paragraph}
{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}


%% Comments
\newif\ifcomments\commentstrue

\ifcomments
\newcommand{\authornote}[3]{\textcolor{#1}{[#3 ---#2]}}
\newcommand{\todo}[1]{\textcolor{red}{[TODO: #1]}}
\else
\newcommand{\authornote}[3]{}
\newcommand{\todo}[1]{}
\fi

\newcommand{\wss}[1]{\authornote{magenta}{SS}{#1}}
\newcommand{\ds}[1]{\authornote{blue}{DS}{#1}}


%% The following are used for pretty printing of events and requirements
\makeatletter

\define@cmdkey      [TP] {test}     {name}       {}
\define@cmdkey      [TP] {test}     {desc}       {}
\define@cmdkey      [TP] {test}     {type}       {}
\define@cmdkey      [TP] {test}     {init}       {}
\define@cmdkey      [TP] {test}     {input}      {}
\define@cmdkey      [TP] {test}     {output}     {}
\define@cmdkey      [TP] {test}     {pass}       {}
\define@cmdkey      [TP] {test}     {user}       {}
\define@cmdkey      [TP] {test}     {reqnum}     {}


\newcommand{\getCurrentSectionNumber}{%
  \ifnum\c@section=0 %
  \thechapter
  \else
  \ifnum\c@subsection=0 %
  \thesection
  \else
  \ifnum\c@subsubsection=0 %
  \thesubsection
  \else
  \thesubsubsection
  \fi
  \fi
  \fi
}

\newcounter{TestNum}

\@addtoreset{TestNum}{section}
\@addtoreset{TestNum}{subsection}
\@addtoreset{TestNum}{subsubsection}

\newcommand{\testauto}[1]{
\setkeys[TP]{test}{#1}
\refstepcounter{TestNum}
\begin{mdframed}[linewidth=1pt]
\begin{tabularx}{\textwidth}{@{}p{3cm}X@{}}
{\bf Test \getCurrentSectionNumber.\theTestNum:} & {\bf \cmdTP@test@name}\\[\baselineskip]
{\bf Description:} & \cmdTP@test@desc\\[0.5\baselineskip]
{\bf Type:} & \cmdTP@test@type\\[0.5\baselineskip]
{\bf Initial State:} & \cmdTP@test@init\\[0.5\baselineskip]
{\bf Input:} & \cmdTP@test@input\\[0.5\baselineskip]
{\bf Output:} & \cmdTP@test@output\\[0.5\baselineskip]
{\bf Pass:} & \cmdTP@test@pass\\[0.5\baselineskip]
{\bf Req. \#:} & \cmdTP@test@reqnum
\end{tabularx}
\end{mdframed}
}

\newcommand{\testmanual}[1]{
\setkeys[TP]{test}{#1}
\refstepcounter{TestNum}
\begin{mdframed}[linewidth=1pt]
\begin{tabularx}{\textwidth}{@{}p{3cm}X@{}}
{\bf Test \getCurrentSectionNumber.\theTestNum:} & {\bf \cmdTP@test@name}\\[\baselineskip]
{\bf Description:} & \cmdTP@test@desc\\[0.5\baselineskip]
{\bf Type:} & \cmdTP@test@type\\[0.5\baselineskip]
{\bf Testers:} & \cmdTP@test@user\\[0.5\baselineskip]
{\bf Pass:} & \cmdTP@test@pass\\[0.5\baselineskip]
{\bf Req. \#:} & \cmdTP@test@reqnum
\end{tabularx}
\end{mdframed}
}

\makeatother

\newcommand{\ZtoT}{
\begin{tabularx}{3.85cm}{@{}p{0.35cm}p{0.35cm}p{0.35cm}p{0.35cm}p{0.35cm}p{0.35cm}p{0.35cm}p{0.35cm}p{0.35cm}p{0.35cm}p{0.35cm}@{}}
0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10
\end{tabularx}
}

\begin{document}
\title{\bf Text to Motion Database\\[\baselineskip]\Large Design Document}
\author{Brendan Duke\\Andrew Kohnen\\Udip Patel\\David Pitkanen\\Jordan Viveiros}
\date{\today}

\maketitle

\pagenumbering{roman}
\tableofcontents
% \listoftables
% \listoffigures


\begin{table}[bp]
\caption*{\bf Revision History}
\begin{tabularx}{\textwidth}{p{3.5cm}p{2cm}X}
\toprule {\bf Date} & {\bf Version} & {\bf Notes}\\
\midrule
January 5, 2017 & 0.0 & File created\\
\bottomrule
\end{tabularx}
\end{table}

\newpage

\pagenumbering{arabic}

\chapter{Overview}
The Text to Motion Database aims to provide a living database of pose estimation and word pairings. This purpose of this document is to provide a detailed description of the design choices for each section of the Text to Motion Database.

\chapter{User Experience}
The following section is used to describe the user expierence while using the web interface. The user experience is meant to describe the user's journey between the web pages and the design choices that were made with respect to the user interface.

\begin{figure}[!ht]
        \caption{McMaster Text-to-Motion Database User Expierence}
        \label{userExp}
        \centering
        \includegraphics[width=0.8\textwidth]{../Docs/data/UserExperience.png}
\end{figure}

\section{User Journey}
When a user first lands on the website they will see the home page. At this point, they will see a header with additional tabs, some information about the application, the software used, and brief instructions for the website. Looking at Figure 1 the next step will be to use one of the tabs found in the header to sign in, register, view the contact information, learn more about the application, view the text-to-motion search page or access the deep learning algorithm to view pose estimated images and video. Upon logging in the user will be taken back to the home page with the ability to create new pose estimated images and video, if the user is not registered they will be taken to the Log In screen where after logging on they are taken to the home page with the ability to now log out.

If the user attempts to upload a new image while they are not logged in they will be taken to the Log In screen and after successfuly logging in they will return to the previous page. This process will be repeated if any additonal functions of the website require the user to be logged in, they will be taken to the log in screen and returned to the previous page after successfuly logging in.

\section{Home Page}
When first arriving to the website the user should be greated with a clean design that informs them of their options without the page being congested or difficult to understand. The home page currently contains plain text to describe the website's function as a Text to Motion Database, along with the additonal softwares used, and instructions. Currently the desing doesn't contain any information about the deep learning algorithm or instructions as an image or video but will be updated to include a user friendly view that catches the eye and keeps the user on the website. In order to keep the users attention the header bar is easy to use and see in order to allow the user quick navigation to other web pages.

\section{About}
The about page contains a high level description of the project overview, problem statement, and what the websites intended function is. The page uses simple plain text but may be updated to include descriptive images or media to better describe the projects overview or function.

\section{Contact}
The contact page has the contact infromation for each group member, along with the internal supervisor, and external supervisors. It uses plain text for the information and clearly labels vital information like email addresses, and positions within the project.

\section{Header}
In order to easily find and access the ability to navigate between pages the header remains at the top of the page with all tabs in the same location. This allows users to create an association between the structure of the header and where they should look to preform an action. Remaining in the same location helps the user expierence and usability of the website.

\section{Log In}
When navigating to the log in page the use is met by a visually clean page, with two text boxes labeled username and password. The text boxes and button below labeled Log In helps eliminate confusion about the page, and helps inform the user of the pages functionality.

\section{Register}
Following the same design as the log in page the register page displays a visually clean page, with labeled text boxes to create a username, passowrd, and confirm the previously entered password.

\section{Text To Motion}
The ability to search the database for a pose estimated image or video is preformed on this page and visually informs the user that through the large search bar and image at the center of the page. The usability of the page is quickly determined as the user has a single clear option for the search bar with an image that helps them determine they are searching through a database.

\subsection{Search Results}
Once the search bar has recieved input it will parse through the database and existing uploads to return uploads that match or have strong ressemblence of the input in a column format. Each result will take the user to a seperate page with the Name, Description and pose estimated media. The layout of the results shows the user what was returned without any additional information to promote the usability and accuracy of the search.

\section{Image Pose Draw}
After landing on the page labeled Image Pose Draw the user is greeted by a table with a Name, Descriptions, and three labeled hyperlinks. This is where the most recent uploads are displayed with their name and description (given during the upload) and the pose estimated media that was uploaded. Looking beyond the table there is a text box labeled Search that allows the user to search through the uploaded images and a hyperlinked label Create that allows the user to upload a new image for pose estimation.

This is the most visually complex screen but is seperated and organized to direct the users attention to the table first and notice the create and search functions after they understand what the page contains. The table conatins simple information and follows typical conventions for labels and hyperlinks that can preform a task in order to help the user understand what will happen as they click or update information. It also seperates the Name from the Desription by using seperate background colours in order to help the user differntiate between the two subsections. The search bar is positioned to the upper right of the table itself to help create the relationship of searching within the table itself. Following the conventions used within the table the Create is hyperlinked in order to promote clicking on it to preform the labels task which takes the user to upload a new image.

\subsection{Create}
Once the user has navigated to the create page they have the ability to upload new media in order to be pose esimated and stored within the database. Uploading the image allows the user to chose an image from storage or by url. In addition to uploading the image there are two text boxes that allow the user to provide a name for the image and short description to provide some information on their uploaded image. Once these steps have been completed using the button labeled create will upload the image and return the user to the ImagePoseDraw page upon completion in order to inform them the task has been completed.

\subsection{Description}
In order to see the uploaded media the user can use the name that the image was uploaded with by using the search box or sorting alphabetically. After the upload was located the user can edit the tags of the image, delete the image and tags, or view the pose estimated media. If the user decides to edit the uploaded image, they are taken to a new screen and given the options to change the Name or Description that was previously input but the media (image or video) itself can not be changed. If the user wants to remove or change their uploaded media they have to first delete their previous upload using the Delete option and go through the steps of creating again. Lastly if the user wants to view the media that has been pose estimated they need to use the Details option which will take them to a new page.

\subsection{Details}
Once on the details page the user sees the Name and Description that was uploaded and the media which currently estimates the chin, and upper arms. Each section is cleary defines with joints being represnted by red circles and arm sections being represented by green lines. This shows the user where the algorithm believes the labeled sections are and the seperation of colour allows for an easy understanding of the positioning.

\chapter{Database Structure}

\section{Database Schema}
\section{Table Description}

\chapter{Module Decomposition}

\section{Text To Motion - ASP.NET Application}


\subsection{Overview}
This component of the application is used to run the web interface and is responsible for linking the database and pose estimation functionality. Performing these tasks relies on 'ASP.net' and the Model, View, Controller (MVC) structure. A general description of ASP.NET and its components will be detailed below
\\\\
\textbf{ASP.NET core:}
\\
framework responsible for handling all http requests to a specific port (\href{159.203.10.112}{Live Website})
\\\\
\textbf{.NET Entity Framework}
\\Object-Relational-Mapper (ORM) that can allow for .NET web apps to perform queries and updates on existing databases (or even create new databases with migration files). This is done through using 'Model' files.

\subsection{Models}

Each Model file represents a 'table' in a database. The Model file contains information on the columns of the 'table' and its relation to other tables in the database.
\\
The current version of the live website does not use the relational database schema described in Section 3 of this document. A simpler schema was used for the prototype
\\\\
Two Models were addded to the .NET web app

    \begin{itemize}
      \item \textbf{ApplicationUsers}
      \\
      The ApplicationUsers model will be used to add profile data to application, but is currently empty as there are no properties being stored.
      \\
      This table gets filled up when users register on the live website

      \item \textbf{PoseDrawnImage}
      \\
      PoseDrawnImage uses the {get; set;} property to store the ID, Description and Name for a given image.

      \begin{itemize}
        \item int ID
        \item string Name
        \item string Description
      \end{itemize}

    \end{itemize}

\subsection{Controllers}

In the ASP.NET web application, every function in a 'Controller' file has a corresponding 'View' file (.cshtml) that is associated with in in the 'Views' folder.
\\\\
A View in the .NET MVC can qualify for the type of \textbf{IActionResult}, and is usually returned by the Controller function
\\\\
HTTP[Get] and HTTP[Post] methods can return a type of \textbf{IActionResult} (sync) or \textbf{Task\textless IActionResult\textgreater} (async)

\subsection{HomeController}
The HomeController is a simple controller that is used to display the Index, About and Contact pages.

\subsubsection{Function: HTTP[Get] Index()}
\begin{itemize}
    \item \textbf{Expected Arguments:}
    \item \textbf{Returns:}

    The View of 'Home/Index.cshtml' in the 'Views' folder of the .NET application

    \item \textbf{Description:}

    Calls the View of 'Index' through the MVC, in order to display the home page
\end{itemize}

\subsubsection{Function: HTTP[Get] About()}
\begin{itemize}
    \item \textbf{Expected Arguments:}
    \item \textbf{Returns:}

    The View of 'Home/About.cshtml' in the 'Views' folder of the .NET application

    \item \textbf{Description:}

    Calls the View of 'About' through the MVC, in order to display the About page
\end{itemize}

\subsubsection{Function: HTTP[Get] Contact()}
\begin{itemize}
    \item \textbf{Expected Arguments:}
    \item \textbf{Returns:}

    The View of 'Home/Contact.cshtml' in the 'Views' folder of the .NET application

    \item \textbf{Description:}

    Calls the View of 'Contact' through the MVC, in order to display the Contact Information
\end{itemize}



\subsection{AccountController}
The AccountController is used in order to verify Register and Login information for a user, using the HTTP Get and Post. It utilizes built in functions of 'ASP.net' but a majority are not being used for revision 0, so they are omitted below.

\subsubsection{Function: HTTP[Get] Login(args)}
\begin{itemize}
    \item \textbf{Expected Arguments:}

    string\quad\textit{returnUrl} = null;

    \item \textbf{Returns:}

    The View of 'Account/Login.cshtml' in the 'Views' folder of the .NET application

    \item \textbf{Description:}

    Displays the Login page and stores the ReturnURL to be taken back into \textit{returnUrl}
\end{itemize}

\subsubsection{Function: HTTP[Post] Login(args)}
\begin{itemize}
    \item \textbf{Expected Arguments:}

    LoginViewModel\quad\textit{model};
    \\
    string\quad\textit{returnUrl} = null;

    \item \textbf{Returns:}

    Returns the user to the previous page if complete.
    \\
    Locks the user out if the number of attempts are exceeded.
    \\
    Refreshes the page if something unexpected occurs.

    \item \textbf{Description:}

    Uses the async feature in order to access the account model.Email, model.Password, model.RememberMe and test the login. After which the reponse is returned in any as one of the above situations.

\end{itemize}


\subsubsection{Function: HTTP[Get] Register(args)}
\begin{itemize}
    \item \textbf{Expected Arguments:}

    string\quad\textit{returnUrl} = null;

    \item \textbf{Returns:}

    The View of 'Account/Register.cshtml' in the 'Views' folder of the .NET application

    \item \textbf{Description:}

    Displays the Register page and stores the ReturnURL to be taken back into \textit{returnUrl}
\end{itemize}


\subsubsection{Function: HTTP[Post] Register(args)}
\begin{itemize}
    \item \textbf{Expected Arguments:}

    RegisterViewModel\quad\textit{model};
    \\
    string\quad\textit{returnUrl} = null;

    \item \textbf{Returns:}

    Upon sucessful registration the user is returned to the previous page.
    \\
    If an error occured within the registration process the user is shown the
    \\
    error or the page is refreshed as something unexpected occured.

    \item \textbf{Description:}

    The function creates a new ApplicationUser and stores the email/username and password in model.Email/Username and model.Password respectivly. They are then signed in or shown the errors that may have occured during the account creation.
\end{itemize}


\subsection{TextToMotionController}

This controller is used to facilitate the 'text-to-motion' search.
\\
As of now, this search functionality has not been implemented due to the lack of a database on the live website. Submitting a search form just passes the search query to the ASP.NET backend and into a new webpage. This will be detailed in the function definitions below

\subsubsection{Function: HTTP[Get] Index()}
\begin{itemize}
    \item \textbf{Expected Arguments:}
    \item \textbf{Returns:}

    The View of 'TextToMotion/Index.cshtml' in the 'Views' folder of the .NET application

    \item \textbf{Description:}

    Returns the View of 'Index' through the MVC, in order to display the Search page (just a simple view with a text input)
\end{itemize}


\subsubsection{Function:: HTTP[Post] Search(args)}
\begin{itemize}
    \item \textbf{Expected Arguments:}

    string\quad\textit{query}

    \item \textbf{Returns:}

    The View of 'TextToMotion/Search.cshtml' in the 'Views' folder of the .NET application with \textit{query} passed into the View

    \item \textbf{Description:}

    Puts the value of \textit{query} into the View. Then, Returns the View of 'Search' through the MVC, which shows the user the search term they entered (This will be built on to actually implement a search functionality)

\end{itemize}


\subsection{ImagePoseDrawController}

This Controller handles the create/view/edit/delete functionalities for images that users upload
\\
This file also imports a shared object file to access a function defined in C. This function is a call to a C++ program that uses OpenCV and Caffe to analyze a given image and draw a skeleton overlay on the image
\\\\
\underline{List of Functions (IPD = ImagePoseDraw)}

\subsubsection{IPD Function 1: Task\textless bool\textgreater DoesImageExist(args)}
\begin{itemize}
    \item \textbf{Expected Arguments:}

    int\quad\textit{id}

    \item \textbf{Returns:}

    \textbf{true} if an model of PoseDrawnImage with id = the \textit{id} passed into the function exists
    \\
    \textbf{false} if no database row found with the given \textit{id}

    \item \textbf{Description:}

    This is just a simple async helper function
\end{itemize}

\subsubsection{IPD Function 2: ImagePoseDrawController(args)}
\begin{itemize}
    \item \textbf{Expected Arguments:}

    ApplicationDbContext\quad\textit{context}
    \\
    IHostingEnvironment\quad\textit{environment}

    \item \textbf{Returns:}

    This function is a Constructor for its class and returns an object of type ImagePoseDrawController

    \item \textbf{Description:}

    The Constructor function is used to set the database session context and environment.
    \\
    \textit{environment} is used to get the absolute path when saving images
\end{itemize}


\subsubsection{IPD Function 3: HTTP[Get] Index()}
\begin{itemize}
    \item \textbf{Expected Arguments:}

    \item \textbf{Returns:}

    The View of 'ImagePoseDraw/Index.cshtml' in the 'Views' folder of the .NET

    \item \textbf{Description:}

    Passes in the list of image names and description into the view. Then, returns the 'Index' View through the MVC, which shows a table of all of the user's uploaded images
\end{itemize}

\subsubsection{IPD Function 4: HTTP[Get] Details()}
\begin{itemize}
    \item int\quad\textit{id}

    \item \textbf{Returns:}

    if \textit{id} is NOT null and a model of type PoseDrawnImage with the given \textit{id} exists, returns the View of 'ImagePoseDraw/Details.cshtml' in the 'Views' folder of the .NET application
    \\\\
    else returns an error obejct

    \item \textbf{Description:}

    Passes in the processed image from the database into the view. Then, returns the 'Details' View, which shows an image with a skeleton overlay on top of the original picture.
\end{itemize}


\subsubsection{Function  : HTTP[Get] Create()}
\begin{itemize}
    \item \textbf{Expected Arguments:}
    \item \textbf{Returns:}

    The View of 'TextToMotion/Create.cshtml' in the 'Views' folder of the .NET application

    \item \textbf{Description:}

    Returns the View of 'Create' through the MVC, which is a form that allows a user to upload an image to run the pose estimation algorithm on
\end{itemize}



...looking to add 3 more funcs...


\break

\section{Flowing Convnets - Human Pose Estimation}

\subsection{Overview}

This component of the project actually renders the skeleton overlay onto an image submitted to the website.
\\
Mapping out the joints of a person in an image requires the use of image manipulation and deep learning libraries. As of now, this proces is based on a research paper and is implemented with \textbf{Caffe} and \textbf{OpenCV} in \textbf{C++}. (*The parameters for functions given below will reference 'caffe' and 'cv' types in c++)


\subsection{Shared Object File}

The website is able to take an uploaded image and process it by using a shared object file (.so). The web app can make function calls to functions in the shared object file and pass in images as the parameters.
\\\\
The C++ file \textbf{"estimate\_pose.cpp"} contains all of the functions that interface with Caffe and OpenCV. The C file \textbf{"estimate\_pose\_wrapper.c"} is used to wrap the C++ function in C, and create the shared object file so that the C++ function can be accessed from the website.

\subsection{Pose Estimation C Program (estimate\_pose\_wrapper.c)}
The file \textbf{"estimate\_pose\_wrapper.c"} just contains 1 function. This function references a C++ function in \textbf{estimate\_pose.cpp}
\\\\
\textbf{Function: int32\_t estimate\_pose\_wrapper(args)}
\begin{itemize}
    \item \textbf{Expected Arguments:}

    void\quad\textit{*image}
    \\
    uint32\_t\quad\textit{*size\_bytes}
    \\
    uint32\_t\quad\textit{max\_size\_Bytes}

    \item\quad\textbf{Returns:}

    if \textit{image} is processed and saved, returns:\\\textbf{int32\_t size}
    (describing size of file that was uploaded)
    \\\\
    else returns error object

    \item \textbf{Description:}

    this function makes a direct call to the C++ function \textbf{"estimate\_pose\_from\_c"} in \textbf{"estimate\_pose.cpp"} and simply returns the result of that C++ function call.
    \\
    The C++ function takes in the same args as this function
\end{itemize}

\subsection{Pose Estimation C++ Program (estimate\_pose.cpp)}

This C++ Program file contains 8 functions. All of these functions take in objects from the 'openCV'(cv) and 'Caffe'(caffe) libraries as arguments
\\\\
The key function in this file is \textbf{estimate\_pose\_from\_c}, and most of the functions serve as helpers to this function
\\\\
\underline{List of Functions and Descriptions (PE = Pose Estimation):}
\\
\subsubsection{References for Objects used in C++ functions}

\begin{itemize}
    \item \textbf{References for OpenCV objects}

    \href{http://docs.opencv.org/3.1.0/d3/d63/classcv_1_1Mat.html#details}{Reference to cv::Mat}
    \\
    \href{http://docs.opencv.org/3.1.0/db/d4e/classcv_1_1Point__.html}{Reference to cv::Point}
    \\
    \href{http://docs.opencv.org/3.1.0/d4/d32/classcv_1_1__InputArray.html}{Reference to cv::InputArray}


    \item \textbf{References for Caffe Objects}

    \href{http://caffe.berkeleyvision.org/doxygen/classcaffe_1_1Blob.html}{Reference to caffe::Blob}
    \\
    \href{http://caffe.berkeleyvision.org/doxygen/classcaffe_1_1Net.html}{Reference to caffe::Net}




    \item \textbf{References for Other Objects}

    \href{http://www.boost.org/doc/libs/1_63_0/libs/smart_ptr/shared_ptr.htm}{Reference to boost::shared\_ptr}

\end{itemize}

\subsubsection{PE Function 1: void channels\_from\_blob(args)}
\begin{itemize}
    \item \textbf{Expected Arguments:}

    std::vector\textless cv::Mat\textgreater\quad\textit{channels}
    \\
    boost::shared\_ptr\textless caffe::Blob\textgreater\quad\textit{blob}
    \\
    int32\_t\quad\textit{width}
    \\
    int32\_t\quad\textit{height}

    \item \textbf{Returns:}

    void (saves data into \textit{channels})

    \item \textbf{Description:}

    The \textit{blob} object contains concatenated mulit-channel data
    \\
    The \textit{channels} object is empty to begin with
    \\
    This function converts the raw data in a Caffe blob into a 'container of channels' (vector of openCV matrices)
    \\
    The \textit{width} and \textit{heigth} parameters let the program know what the dimensions of the channels are in the \textit{blob}
    \\
    The extracted information from \textit{blobs} is saved into the \textit{channels} vector
    \\\\
    This function is just used as a helper for other functions
\end{itemize}


\subsubsection{PE Function 2: void copy\_image\_to\_input\_blob(args)}
\begin{itemize}
    \item \textbf{Expected Arguments:}

    caffe::Net \textless float\textgreater\quad\textit{heatmap\_net}
    \\
    cv::Mat\quad\textit{image}

    \item \textbf{Returns:}

    void (saves data into \textit{heatmap\_net})

    \item \textbf{Description:}

    This function converts the \textit{image} object from OpenCV BGR format to 32-bit-floating point RGB format and copies the image to the input blob of \textit{heatmap\_net}. It lso divides the input layer of the \textit{heatmap\_net} from a multi-channel array into several single-channel arrays by calling a helper function
    \\
    \textit{image} is the image that will serve as the input layer to the caffe network
    \\
    \textit{heatmap\_net} is the caffe network that will get its input layer filled with the RGB pixel data from \textit{image}
    \\\\
    This function makes a call to \textbf{PE-cpp Function 1} when it splits up the newly updated image in \textit{heatmap\_net}'s input layer into several 'input\_channels'
\end{itemize}


\subsubsection{PE Function 3: void get\_joints\_from\_network(args)}
\begin{itemize}
    \item \textbf{Expected Arguments:}

    cv::Point \quad\textit{*joints}
    \\
    cv::Size \quad\textit{channel\_size}
    \\
    caffe::Net\textless float\textgreater\quad\textit{heatmap\_net}

    \item \textbf{Returns:}

    void (saves data into \textit{joints})

    \item \textbf{Description:}

    This function uses the \textit{heatmap\_net}'s "conv5\_fusion" layer to get a set of joint locations for that heatmap. (This layer is derived from the research paper used)
    \\
    The joint locations get saved into \textit{*joints}
    \\
    The \textit{channel\_size} is used to maintain the accuracy of the position of the joints relative to the image as the image matrix is resized multiple times
    \\\\
    This function makes a call to \textbf{PE-cpp Function 1} when it uses the \textit{heatmap\_net} to save all of the joint locations in a 'joint\_channel' vector of cv::Mat objects
\end{itemize}


\subsubsection{PE Function 4: void draw\_skeleton(args)}
\begin{itemize}
    \item \textbf{Expected Arguments:}

    cv::Mat \quad\textit{image}
    \\
    cv::Point \quad\textit{*joints}

    \item \textbf{Returns:}

    void (saves image data into \textit{image})

    \item \textbf{Description:}

    This function uses the joint\_locations described in \textit{*joints} to draw an upper-body skeleton on the \textit{image} matrix passed in.
    \\
    \textit{image} is the image to draw the skeleton overlay on
    \\
    \textit{*joints} contain the locations for the set of joints (wrists, elbows, shoulders and head)
\end{itemize}

\subsubsection{PE Function 5: std::unique\_ptr\textless caffe::Net\textless float\textgreater\textgreater init\_pose\_estimator\_network(args)}
\begin{itemize}
    \item \textbf{Expected Arguments:}

    std::string\quad\textit{model}
    \\
    std::string\quad\textit{trained\_weights}

    \item \textbf{Returns:}

    \textbf{std::unique\_ptr\textless caffe::Net\textless float\textgreater\textgreater} heatmap\_net
    \\
    pointer to an object that represents a whole caffe network

    \item \textbf{Description:}

    This function creates a Caffe network and copies over the trained layers from a given option for \textit{trained\_weights}
    \\
    For this application, a caffe network is initialized with the default settings:
    \\
    (\textit{model} = 'MODEL\_DEFAULT', \textit{trained\_weights} = TRAINED\_WEIGHTS\_DEFAULT)
\end{itemize}


\subsubsection{PE Function 6: void image\_pose\_overlay(args)}
\begin{itemize}
    \item \textbf{Expected Arguments:}

    caffe::Net\textless float\textgreater\quad\textit{heatmap\_net}
    \\
    cv::Mat\quad\textit{image}

    \item \textbf{Returns:}

    void (saves to \textit{image})

    \item \textbf{Description:}

    This function processes the \textit{image} passed in using the \textit{heatmap\_net} to draw a skeleton on the openCV Matrix
    \\\\
    Details on the actions taken by the function:
    \begin{enumerate}
        \item Resizes \textit{image} to 256x256

        \item calls \textbf{PE Function 2} to copy the image into the input layer of the \textit{heatmap\_net}

        \item after allowing the network to extract some data, declares an array object of cv::Point called \textit{joints}

        \item calls \textbf{PE Function 3} to load in joint locations into \textit{joints}

        \item converts image to a format so that it can be drawn on by the program

        \item calls \textbf{PE Function 4} to draw the skeleton overlay on top of the \textit{image}
    \end{enumerate}
\end{itemize}


\subsubsection{PE Function 7: void square\_image\_with\_borders(args)}
\begin{itemize}
    \item \textbf{Expected Arguments:}

    cv::Mat\quad\textit{image\_mat}

    \item \textbf{Returns:}

    void (saves image data to \textit{image\_mat})

    \item \textbf{Description:}

    If the image's dimensions do not fit a square (length != width), this function makes it so that the image dimensions are expanded so that it fits into a square
    \\
    This is to avoid distorting the image drastically when the image is resized to 256x256
    \\\\
    This is just a simple helper function to pre-process the image
\end{itemize}



\subsubsection{PE Function 8: int32\_t estimate\_pose\_from\_c(args)}
\begin{itemize}
    \item \textbf{Expected Arguments:}

    void\quad\textit{*image}
    \\
    uint32\_t\quad\textit{*size\_bytes}
    \\
    unit32\_t\quad\textit{max\_size\_bytes}

    \item \textbf{Returns:}

    if \textit{image} is processed and saved, returns:\\\textbf{int32\_t size}
    (describing size of file that was uploaded)
    \\\\
    else returns error object

    \item \textbf{Description:}

    This function is the key method in this file. This function overwrites the contents of the memory allocated for \textit{*image} so that a given image is updated to show the skeleton overlay on that image
    \\\\
    This function creates a new Caffe network and calls a lot of helper functions needed to process the \textit{image}
    \\\\
    Details on the actions taken by the function:
    \begin{enumerate}
        \item calls \textbf{PE Function 5} to create a new caffe Network, stores new network in \textit{heatmap\_net}

        \item uses \textit{*image} and \textit{*size\_bytes} to create a cv::InputArray object to represent the uploaded image

        \item creates a cv::Mat image matrix, and decodes the contents of the cv::InputArray object into the newly created matrix object

        \item calls \textbf{PE Function 7} to pre-process the image matrix to reaffirm that the image is square

        \item calls \textbf{PE Function 6} using \textit{heatmap\_net} and the image matrix so that the image\_matrix includes the skeleton overlay

        \item converts and compresses the image\_matrix into a png

        \item finally, overwrites the contents of \textit{*image} with the newly created image that has the pose estimation 'skeleton overlay'
    \end{enumerate}

\end{itemize}


\break

\section{Features In Development}

\subsection{Pose Estimation For Videos (C++)}

Since a video can be considered as just a set (or array) of images, this pose estimation algorithm can be executed on videos as well as images. At this point in the project,a C++ program does exist that references a function from the file \textbf{"estimate\_pose.cpp"} to analyze videos, but the code has not been finalized. It is also far too slow to be used from a web interface.
\\\\
Since this functionality is not a part of the system yet, this module was not given a formal declaration/definition. In addition to the reasons mentioned above, the Caffe submodule as a whole will soon be replaced by a newer deep learning framework described in the section below (Tensorflow). So this module is not going to be included in the final revision of this document

\subsection{Tensorflow}

Moving Forward, the Caffe deep learning framework (C++) will be replaced by Tensorflow. Tensorflow is a newer framework with more support for developers compared to Caffe. Tensorflow is a library in Python that can generate graphs needed for neural networks and deep learning algorithms. Replacing the deep learning framework will not drastically change the logic of the web application. The web application would just refer to a different kind of executable when processing an uploaded image (it refers to a shared object file as of now).
\\\\
The project repository contains several test Python files and functions that work with the simpler aspects of Tensorflow. These are attempts at trying to learn Tensorflow and the functions or files are not referenced by the ASP.NET web app at all. Since these files are separate from the functionality of the main application, these modules detailing Tensorflow test code have not been included in the design documentation.

\subsection{Standalone HTTP Server}



\chapter{Communication Protocol}

...just mention to HTTP...


\chapter{Development Details}

\section{Languages}
\section{Software}
\section{Hardware}


\end{document}
