\documentclass{scrreprt}

\usepackage{xcolor} % for different colour comments
\usepackage{tabto}
\usepackage{mdframed}
\mdfsetup{nobreak=true}
\usepackage{xkeyval}
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=red,
    urlcolor=blue
}
\usepackage[skip=2pt, labelfont=bf]{caption}
\usepackage{titlesec}
\usepackage{graphicx}
\usepackage[section]{placeins}
\graphicspath{ {../data/} }

\titleformat{\paragraph}
{\normalfont\normalsize\bfseries}{\theparagraph}{1em}{}
\titlespacing*{\paragraph}
{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}


%% Comments
\newif\ifcomments\commentstrue

\ifcomments
\newcommand{\authornote}[3]{\textcolor{#1}{[#3 ---#2]}}
\newcommand{\todo}[1]{\textcolor{red}{[TODO: #1]}}
\else
\newcommand{\authornote}[3]{}
\newcommand{\todo}[1]{}
\fi

\newcommand{\wss}[1]{\authornote{magenta}{SS}{#1}}
\newcommand{\ds}[1]{\authornote{blue}{DS}{#1}}


\begin{document}
\title{\bf Text to Motion Database\\[\baselineskip]\Large Detailed Design}
\author{Brendan Duke\\Andrew Kohnen\\Udip Patel\\David Pitkanen\\Jordan Viveiros}
\date{\today}

\maketitle

\pagenumbering{roman}
\tableofcontents
% \listoftables
% \listoffigures


\begin{table}[bp]
\caption*{\bf Revision History}
\begin{tabularx}{\textwidth}{p{3.5cm}p{2cm}X}
\toprule {\bf Date} & {\bf Version} & {\bf Notes}\\
\midrule
January 5, 2017 & 0.0 & File created\\
\bottomrule
\end{tabularx}
\end{table}

\newpage

\pagenumbering{arabic}

\chapter{Overview}

The Text to Motion Database aims to provide a living database of pose estimated
media with word pairings and tags. The purpose of this document is to provide a
detailed description of the design choices for each section of the Text to
Motion Database.

\chapter{User Experience}

A user experience is the overall journey of a person on the Text to Motion
Database with respect to learnability and usability. This section is organized
to describe the journey between web pages and any design choices that went into
the user interface in order to improve the overall experience.

\begin{figure}[!ht]
        \caption{McMaster Text-to-Motion Database User Expierence}
        \label{userExp}
        \centering
        \includegraphics[width=0.8\textwidth]{../data/UserExperience.png}
\end{figure}

\section{User Journey}

As seen in Figure~\ref{userExp}, when a user comes to the Text to Motion
Database they will see the home page. At first glance they see some information
about the website and how it can be used along with some different page options
located at the top. Each of these different pages displays something different
and is hinted at within the name of the page, with ImagePoseDraw being the most
ambiguous. All the pages can be accessed by an anonymous user, but in order to
upload media a user must register or sign in. Each page will be described in
greater detail below with additional functionality and design choices.

\section{Home Page}

As previously mentioned the first page seen on the Text to Motion Database is
the home page. It contains an application description, resources that were
used, and brief instructions on how to use the website. The overall design of
the page was to be simple and present the information to the user front and
center so that they could explore the options given to them on their own.

\section{About}

The about page is a more granular description of the Text to Motion Databaseâ€™s
overview, problem statement and what the intended use of the website is. Like
the home page a simple design and colour scheme were chosen along with plain
text for easier reading.

\section{Contact}

The contact page maintains the overall look and feel of the website with plain
text and individual boxes for the contact information of each group member and
supervisors. Every box contains the member's name and e-mail at minimum, with
the addition of titles for each supervisor and the department for each group
member.

\section{Navigation Bar}

In order to maintain an easy way to navigate the website, the navigation bar
located at the top of the page contains links to each page with fixed locations
regardless of which page the user is currently on. This allows the users to
learn the link location and makes for a more enjoyable experience.

\section{Log In}

If the user has already made an account with the Text to Motion Database they
can use the login page to access the account in order to upload images and
video. While on the login page before successfully logging in the page location
on the navigation bar is in the far right corner, and after logging in it is
replaced by the option to log off.

From a design standpoint the login page contains two text boxes for entry, an
option for the username to be remembered, a login button, and hyperlinks to
register or recover a lost password. Overall it is a very standard login screen
and should help a first time user navigate through without any confusion or
misunderstanding.

\section{Register}

If the user has not already made an account, and wishes to do, so the option to
register can be accessed from the navigation bar or the login page. It follows
the same website standards that the login page does and has three text boxes
for a username, password and password confirmation along with the button to
complete a registration. Once a user has made an account or successfully logged
in, the register option in the navigation bar will be replaced by a greeting
and take them to the account management options, which at revision 0 are not
fully complete.

\section{Text To Motion}

Searching the database is not restricted by a given user's account and rather
can be accessed by anyone, since it is one of the core features of the Text to
Motion Database. The ability to search through the pose estimated data is done
through the large search bar on the page, helping the user focus on it in order
to explain the functionality of the page.

\subsection{Search Results}

Once the search bar has received input it will parse through the database to
return uploads that match or have strong resemblance of the input in a column
format. Each result will take the user to a separate page with the Name,
Description and pose estimated media. The layout of the results shows the user
what was returned without any additional information to promote the usability
and accuracy of the search.

\section{Image Pose Draw}

Once the user has navigated to the page labeled ImagePoseDraw, the initial view
is that of a table with names, descriptions and hyperlinks. This is currently
where the most recent uploads are displayed with the name and description that
were given during the upload process. The table is designed to contrast
consecutive uploads through a dark and light shading in order to easy
distinguish two different entries. Beyond the table, the page has two other key
functions in the ability to search through the table with by the name or
description, and to create new pose estimated uploads through the hyperlink
above the table.

\subsection{Create}

If the option to create a new entry has been selected, the user is taken to a
new page where they have the ability to upload a new image to be pose estimated
and stored within the database. Choosing the image to upload can be done from a
URL or internal storage, which opens a file explorer when selected. After an
image has been picked, the user has to provide a name and description for the
image before it has been pose estimated so that once stored the result can be
retrieved from the database using a search option. Upon completion of the above
steps the image can be uploaded, taking the user back to the ImagePoseDraw page
with the new entry after the processing has happened.

\subsection{Description}

In order to see the uploaded media the user can use the name associated with an
image to find it by searching or scrolling through alphabetically. After the
upload is located, the user can edit the tags of the image, delete the image
and tags, or view the pose estimated media. Deciding to edit the upload takes
them to a new screen where the options to change the name or description that
were previously input are given. As of revision 0, if the user wants to remove
or change their uploaded image they have to first delete the previous entry
using the Delete option and go through the steps of creating an upload again.
If the user wants to view the selected entry the details option will take them
to a new page to view this.

\subsection{Details}

On the details page the user can see the name and description that was chosen
at the time of the upload and the image that has been pose estimated to show
the chin, and upper arms. Each section of the image is clearly defined with the
chin and joints being represented by red circles and the upper arms being
represented by two green lines connected at a joint. This shows the user where
the algorithm believes the labeled sections are and the separation of colour
allows for an easy understanding of the positioning.

\section{Media Upload}

The process that a verified user can go through in order to upload and interact
with the Text-to-Motion Database is enumerated below.

\begin{enumerate}
        \item The user must first be logged into the website in order to upload an
                image or video.

        \item Using the web interface allows the user multiple options with
                respect to uploading images and video.

        \item The ASP.NET Core web server accesses the TensorFlow backend via
                HTTP request in order to run pose estimation.
                
        \item The ASP.NET Core web server converts the human pose annotations
                into the required HDF5 format for storage in the database.

        \item The database takes in search queries from the ASP.NET Core web
                server and receives uploads from the pose estimation process.
\end{enumerate}

\chapter{Database Structure}

\section{Database Schema}

The Figure below shows an entity relationship diagram for the current iteration
of the database schema. The live website does not use this schema, as the full
implementation of the database is still underway.

\begin{figure}[!ht]
    \caption{Database Entity-Relationship Diagram}
    \label{erDiagram}
	\centering
	\includegraphics[width=0.8\textwidth]{../data/ER-Diagram.png}
\end{figure}

\section{Table Description}

\subsection{Intro}

For better logging, every table will contain dateTime columns for 'created\_at'
and 'updated\_at' to store the appropriate time values. in the table
descriptions below, these 2 datetime columns will be referred to as
\textbf{timestamps}.

Primary keys will be \underline{underlined}, and foreign keys will be
\textit{italicized}

\subsection{user:}

stores user credentials

(\underline{id}, first\_name, last\_name, username, password, \textbf{timestamps})

\subsection{group:}

stores information on a group of images/videos that were uploaded together in a group.

(\underline{id}, name, description, num\_of\_files, total\_size, \textbf{timestamps})

Moving forward, this has the possibility to change to allow for dynamically
grouping files in the database


\subsection{media:}

stores information on the actual image uploaded

(\underline{id}, type = 'image'/'video', accuracy, size, vid\_length == null
for images, \textit{user\_id}, \textit{group\_id} == can be set to null,
\textbf{timestamps})


\subsection{tags:}

stores any word that is generated by the deep learning algorithm that describes
movement or action.

(\underline{id}, classification = 'noun'/'verb'/'adjective',
\textbf{timestamps})


\subsection{media\_tags:}

links together media and tags to describe when a tag was picked up in an image/video

(\underline{id}, tag\_pickup\_time == NULL for imgs, a time object for videos,
\textit{media\_id}, \textit{tag\_id}, \textbf{timestamps})

\chapter{Module Decomposition}

\section{Text To Motion - ASP.NET Application}

\subsection{Overview}

This component of the application is used to run the web interface and is
responsible for linking the database and pose estimation functionality.
Performing these tasks relies on 'ASP.net' and the Model, View, Controller
(MVC) structure. A general description of ASP.NET and its components will be
detailed below

\textbf{ASP.NET core:}

framework responsible for handling all http requests to a specific port (\href{https://brendanduke.ca}{Live Website})

\textbf{.NET Entity Framework}
Object-Relational-Mapper (ORM) that can allow for .NET web apps to perform
queries and updates on existing databases (or even create new databases with
migration files). This is done through using 'Model' files.

\subsection{Models}

Each Model file represents a 'table' in a database. The Model file contains
information on the columns of the 'table' and its relation to other tables in
the database.

The current version of the live website does not use the relational database
schema described in Section 3 of this document. A simpler schema was used for
the prototype

Two Models were addded to the .NET web app:

\begin{itemize}
        \item \textbf{ApplicationUsers}

                The ApplicationUsers model will be used to add profile data to
                application, but is currently empty as there are no properties
                being stored.

                This table gets filled up when users register on the live website

        \item \textbf{PoseDrawnImage}

                PoseDrawnImage uses the {get; set;} property to store the ID, Description
                and Name for a given image.

                \begin{itemize}
                        \item int ID
                        \item string Name
                        \item string Description
                \end{itemize}

\end{itemize}

\subsection{Controllers}

In the ASP.NET web application, every function in a 'Controller' file has a
corresponding 'View' file (.cshtml) that is associated with in in the 'Views'
folder. These files are written in ASP.NET's razor template syntax.

A View in the .NET MVC can qualify for the type of \textbf{IActionResult}, and
is usually returned by the Controller function

Most of the functions inject some text into the View before rendering it. This
is just done through the ASP.NET razor markup syntax, which allows for the
backend controller to pass information to the
view.\href{https://docs.microsoft.com/en-us/aspnet/core/mvc/views/razor}
{Reference to Razor}

HTTP[Get] and HTTP[Post] methods can return objects of type
\textbf{IActionResult} (sync) or \textbf{Task\textless
IActionResult\textgreater} (async)

\subsection{HomeController}

The HomeController is a simple controller that is used to display the Index,
About and Contact pages.

\subsubsection{Function: HTTP[Get] Index()}

\begin{itemize}
        \item \textbf{Expected Arguments:}
        \item \textbf{Returns:}

                The View of 'Home/Index.cshtml' in the 'Views' folder of the
                .NET application

        \item \textbf{Description:}

                Calls the View of 'Index' through the MVC, in order to display
                the home page
\end{itemize}

\subsubsection{Function: HTTP[Get] About()}

\begin{itemize}
        \item \textbf{Expected Arguments:}
        \item \textbf{Returns:}

                The View of 'Home/About.cshtml' in the 'Views' folder of the .NET application

        \item \textbf{Description:}

                Calls the View of 'About' through the MVC, in order to display the About page
\end{itemize}

\subsubsection{Function: HTTP[Get] Contact()}

\begin{itemize}
        \item \textbf{Expected Arguments:}
        \item \textbf{Returns:}

                The View of 'Home/Contact.cshtml' in the 'Views' folder of the
                .NET application

        \item \textbf{Description:}

                Calls the View of 'Contact' through the MVC, in order to
                display the Contact Information
\end{itemize}


\subsection{AccountController}

The AccountController is used in order to verify Register and Login information
for a user, using the HTTP Get and Post. It utilizes built in functions of
'ASP.net'.

\subsubsection{Function: HTTP[Get] Login(args)}

\begin{itemize}
        \item \textbf{Expected Arguments:}

                string\quad\textit{returnUrl} = null;

        \item \textbf{Returns:}

                The View of 'Account/Login.cshtml' in the 'Views' folder of the
                .NET application

        \item \textbf{Description:}

                Displays the Login page and stores the ReturnURL to be taken
                back into \textit{returnUrl}
\end{itemize}

\subsubsection{Function: HTTP[Post] Login(args)}

\begin{itemize}
        \item \textbf{Expected Arguments:}

                LoginViewModel\quad\textit{model};

                string\quad\textit{returnUrl} = null;

        \item \textbf{Returns:}

                Returns the user to the previous page if complete.

                Locks the user out if the number of attempts are exceeded.

                Refreshes the page if something unexpected occurs.

        \item \textbf{Description:}

                Uses the async feature in order to access the account
                model.Email, model.Password, model.RememberMe and test the
                login. After which the reponse is returned in any as one of the
                above situations.

\end{itemize}


\subsubsection{Function: HTTP[Get] Register(args)}

\begin{itemize}
        \item \textbf{Expected Arguments:}

                string\quad\textit{returnUrl} = null;

        \item \textbf{Returns:}

                The View of 'Account/Register.cshtml' in the 'Views' folder of the .NET
                application

        \item \textbf{Description:}

                Displays the Register page and stores the ReturnURL to be taken back into
                \textit{returnUrl}
\end{itemize}


\subsubsection{Function: HTTP[Post] Register(args)}

\begin{itemize}
        \item \textbf{Expected Arguments:}

                RegisterViewModel\quad\textit{model};

                string\quad\textit{returnUrl} = null;

        \item \textbf{Returns:}

                Upon sucessful registration the user is returned to the
                previous page.

                If an error occured within the registration process the user is
                shown the

                error or the page is refreshed as something unexpected occured.

        \item \textbf{Description:}

                The function creates a new ApplicationUser and stores the
                email/username and password in model.Email/Username and
                model.Password respectivly. They are then signed in or shown
                the errors that may have occured during the account creation.
\end{itemize}


\subsection{TextToMotionController}

This controller is used to facilitate the 'text-to-motion' search.

As of now, this search functionality has not been implemented due to the lack
of a database on the live website. Submitting a search form just passes the
search query to the ASP.NET backend and into a new webpage. This will be
detailed in the function definitions below

\subsubsection{Function: HTTP[Get] Index()}

\begin{itemize}
        \item \textbf{Expected Arguments:}
        \item \textbf{Returns:}

                The View of 'TextToMotion/Index.cshtml' in the 'Views' folder
                of the .NET application

        \item \textbf{Description:}

                Returns the View of 'Index' through the MVC, in order to
                display the Search page (just a simple view with a text input)
\end{itemize}


\subsubsection{Function:: HTTP[Post] Search(args)}

\begin{itemize}
        \item \textbf{Expected Arguments:}

                string\quad\textit{query}

        \item \textbf{Returns:}

                The View of 'TextToMotion/Search.cshtml' in the 'Views' folder
                of the .NET application with \textit{query} passed into the
                View

        \item \textbf{Description:}

                Puts the value of \textit{query} into the View. Then, Returns
                the View of 'Search' through the MVC, which shows the user the
                search term they entered (This will be built on to actually
                implement a search functionality)

\end{itemize}


\subsection{ImagePoseDrawController}

This Controller handles the create/view/edit/delete functionalities for images
that users upload.

This file also imports a shared object file to access a function defined in C.
This function is a call to a C++ program that uses OpenCV and Caffe to analyze
a given image and draw a skeleton overlay on the image\href{http://caffe.berkeleyvision.org/doxygen/index.html}{Reference to Caffe}.
\href{http://docs.opencv.org/3.1.0/}{Reference to OpenCV}

\underline{ \textbf{List of Functions (IPD = ImagePoseDraw)}}

\subsubsection{IPD Function 1: Task\textless bool\textgreater
               DoesImageExist(args)}

\begin{itemize}
        \item \textbf{Expected Arguments:}

                int\quad\textit{id}

        \item \textbf{Returns:}

                \textbf{true} if an model of \textbf{PoseDrawnImage} with id =
                the \textit{id} passed into the function exists

                \textbf{false} if no database row found with the given
                \textit{id}

        \item \textbf{Description:}

                This is just a simple async helper function.

                It references the Entity Model \textbf{PoseDrawnImage}
\end{itemize}

\subsubsection{IPD Function 2: ImagePoseDrawController(args)}

\begin{itemize}
        \item \textbf{Expected Arguments:}

                ApplicationDbContext\quad\textit{context}

                IHostingEnvironment\quad\textit{environment}

        \item \textbf{Returns:}

                This function is a Constructor for its class and returns an
                object of type ImagePoseDrawController

        \item \textbf{Description:}

                The Constructor function is used to set the database session
                context and environment.

                It assigns \textit{context} and \textit{environment} default
                values determined by global variables.

                \textit{environment} is used to get the absolute path when
                saving images
\end{itemize}


\subsubsection{IPD Function 3: HTTP[Get] Index()}

\begin{itemize}
        \item \textbf{Expected Arguments:}

        \item \textbf{Returns:}

                The View of 'ImagePoseDraw/Index.cshtml' in the 'Views' folder
                of the .NET

        \item \textbf{Description:}

                Passes in the list of image names and description into the
                view. Then, returns the 'Index' View through the MVC, which
                shows a table of all of the user's uploaded images

                makes a reference to the \textbf{PoseDrawnImage} model when it
                queries all of the names and descriptions of the images that
                have been captured by the database
\end{itemize}

\subsubsection{IPD Function 4: HTTP[Get] Details()}

\begin{itemize}
        \item int\quad\textit{id}

        \item \textbf{Returns:}

                if \textit{id} is NOT null and a model of type PoseDrawnImage
                with the given \textit{id} exists, returns the View of
                'ImagePoseDraw/Details.cshtml' in the 'Views' folder of the
                .NET application

                else returns an error obejct

        \item \textbf{Description:}

                Passes in the processed image from the database into the view.
                Then, returns the 'Details' View, which shows an image with a
                skeleton overlay on top of the original picture.

                Again, this function also makes a reference to the
                \textbf{PoseDrawnImage} model
\end{itemize}


\subsubsection{IPD Function 5: HTTP[Get] Create()}

\begin{itemize}
        \item \textbf{Expected Arguments:}
        \item \textbf{Returns:}

                The View of 'TextToMotion/Create.cshtml' in the 'Views' folder of the .NET
                application

        \item \textbf{Description:}

                Returns the View of 'Create' through the MVC, which is a form that allows a
                user to upload an image to run the pose estimation algorithm on
\end{itemize}



\subsubsection{IPD Function 6: HTTP[Post] Create(args)}

\begin{itemize}
        \item \textbf{Expected Arguments:}

                \textbf{PoseDrawnImage}\quad\textit{posedImage}

                IFormFile\quad\textit{image}\quad\quad\quad\href{https://docs.microsoft.com/en-us/aspnet/core/api/microsoft.aspnetcore.http.iformfile}{[
                        Reference to IFormFile ]}

        \item \textbf{Returns:}

                If the process is completed with no errors, returns the View
                'ImagePoseDraw/Index.cshtml'

                if any error is caught, returns the View
                'ImagePoseDraw/Create.cshtml' so that the user can submit the
                request again as a form

        \item \textbf{Description:}

                the model \textbf{PoseDrawnImage} \textit{posedImage} stores
                'metadata' for the image that gets overlaid with a sketch of
                joint positions. This can be considered metadata because this
                model stores the location of the image (best case: URL,
                system-as-is: file path to SQLite DB on the live website
                server)

                The \textit{image} is the uploaded image that will have a
                skeleton overlay drawn onto it

                The function inserts a new entry into the pose estimation
                database table by creating a new row with a unique ID (in
                ASP.NET, this inclues built-in error checks). The function
                takes in \textit{image} and saves it to a file path, and the
                \textit{posedImage} model has an attribute/value that stores
                the file path that the image is saved in. In order to actually
                analyze the \textit{image}, the function calls the
                ``estimate\_pose\_wrapper'' function from a shared object file.
                This shared object file's function (originally written in C++)
                takes in the raw image, writes the skeleton overlay outline of
                joints onto the raw image and returns it.

                The object referred to in the shared object file will be
                discussed in detail in the next section.

                Once the image has been processed and overwritten to include
                the pose estimation data (joint positions), \textit{posedImage}
                is saved to the database
\end{itemize}

\subsubsection{IPD Function 7: HTTP[Get] Edit()}

\begin{itemize}
        \item \textbf{Expected Arguments:}
        \item \textbf{Returns:}

                The View of 'ImagePoseDraw/Edit.cshtml' in the 'Views' folder
                of the .NET application

        \item \textbf{Description:}

                Returns the View of 'Edit' through the MVC, which displays the
                page where the Name and Description of an upload can be
                manipulated.
\end{itemize}


\subsubsection{IPD Function 8: HTTP[Post] Edit(args)}

\begin{itemize}
        \item \textbf{Expected Arguments:}

                int\quad\textit{id}

                \textbf{PoseDrawnImage}\quad\textit{image}

        \item \textbf{Returns:}

                If the process is completed with no errors, returns the View
                'ImagePoseDraw/Index.cshtml'

                else returns back to the Edit page so the user can re-submit
                the form

        \item \textbf{Description:}

                \textit{id} refers to the id of the \textbf{PoseDrawnImage}
                model to update

                Takes in text input for the new 'Name' and/or 'Description' via
                the HTTP Request

                Updates the content of the pose-drawn image database entry
                (columns for Name and Description).

\end{itemize}

\subsubsection{IPD Function 9: HTTP[Get] Delete()}

\begin{itemize}
        \item \textbf{Expected Arguments:}

                int\quad\textit{id}

        \item \textbf{Returns:}

                if the The View of 'ImagePoseDraw/DElet.cshtml' with the upload
                associated with the \textit{id} removed if confirmation was
                successful, otherwise returns to the ImagePoseDraw page with
                the uploads still there.

        \item \textbf{Description:}

                Calls await Details(id) in order to confirm the removing of the
                upload.
\end{itemize}



\subsubsection{IPD Function 10: HTTP[Post] DeleteConfirmation(args)}

\begin{itemize}
        \item \textbf{Expected Arguments:}

                int\quad\textit{id}

        \item \textbf{Returns:}

                If the process is completed with no errors, returns the View
                'ImagePoseDraw/Index.cshtml', which will no longer show the
                upload associated with the \textit{id}

        \item \textbf{Description:}

                \textit{id} refers to the id of the \textbf{PoseDrawnImage} model to delete

                Uses the database \_context and \textbf{PoseDrawnImages} model
                in order to remove the image when confirmed. Then redirects to
                the ImagePoseDraw/Index.cshtml page.

\end{itemize}

\section{tf-http-server - Human Pose Interface Server}

\subsection{Overview}

This component of the project actually provides an HTTP interface through which
human pose estimation can be run on images and video. The tf-http-server is
written in python and interfaces with the TensorFlow and the human\_pose\_model
directly.

\subsection{tf\_http\_server.py}

\textbf{Function: \_get\_image\_joint\_predictions(args)}
\begin{itemize}
        \item \textbf{Expected Arguments:}

                \textit{image}: JPEG image in raw bytes format.

                \textit{session}: TF session to run inference in.

                \textit{image\_bytes\_feed}: Placeholder tensor to feed image
                into.

                \textit{logits\_tensor}: Output logits tensor, corresponding to
                heatmaps of joint positions inferred by the network.

    \item \textbf{Returns:}

            The joint predictions of a single image in a JSON string.

    \item \textbf{Description:}

            This function does joint position inference on a single image, and returns
                the resultant joint predictions in a JSON string.

                The returned JSON string has the following format:

\begin{verbatim}
[{"r_ankle": [0.5, 0.5], "r\_knee": [1.0, 2.0], ...},
 {"r_ankle": [0.25, 0.2], "r\_knee": [0.1, 0.5], ...}].
\end{verbatim}

                I.e. it is a JSON array of dictionaries, where the keys are
                names of joints from \verb|JOINT_NAMES_NO_SPACE|, and the
                values are two-element arrays containing the \verb|[x, y]|
                coordinates of the joint prediction.

                These \verb|[x, y]| coordinates are in a space where the range
                \verb|[-0.5, 0.5]| represent the range, in the padded image,
                from the far left to the far right in the case of x, and from
                the top to the bottom in the case of y.

\end{itemize}

\textbf{Function: TFHttpRequesthandlerFactory(args)}
\begin{itemize}
    \item \textbf{Expected Arguments:}

            \quad\textit{session}

            \quad\textit{image\_bytes\_feed}

            \quad\textit{logits\_tensor}

            \quad\textit{resized\_image\_tensor}

    \item \textbf{Returns:}

            This function returns a subclass of the \verb|http.server.BaseHTTPrequestHandler|.

    \item \textbf{Description:}

            This function is required to call the subclass of the
                \verb|http.server.BaseHTTPrequestHandler| as it allows the function
                to call extra parameters which are local to the class. All of
                this is required as the constructor expects a certain function
                signature.

\end{itemize}

\textbf{Function: \_respond\_with\_joints(args)}
\begin{itemize}
    \item \textbf{Expected Arguments:}

            \quad\textit{self}

            \quad\textit{image}

    \item \textbf{Returns:}

            Returns a 200 OK HTTP response message with response data as a JSON
                string containing the inferred joint position.

    \item \textbf{Description:}

            Takes the image and performs joint inference on it in order to
                store it within the JSON that is returned containing the
                inferred joint position.

\end{itemize}

\textbf{Function: do\_GET(args)}
\begin{itemize}
    \item \textbf{Expected Arguments:}

           \quad\textit{self}

    \item \textbf{Returns:}

            A JSON string of the estimated joints for the image URL that has
                been passed as an option parameter.

    \item \textbf{Description:}

            This representation of an HTTP GET request will take an image URL
                as a JPEG and perform joint inference on the image in order to
                save it in as a JSON string that will later be returned.

\end{itemize}

\textbf{Function: do\_POST(args)}
\begin{itemize}
    \item \textbf{Expected Arguments:}

            \quad\textit{self}

    \item \textbf{Returns:}

            A JSON string that represents the inferred joint position.

    \item \textbf{Description:}

            This function is a HTTP POST request containing a JPEG in base 64
                in order to decode the base 64 image and perform joint
                inference in order to store it as a JSON string representing
                the joint position.

\end{itemize}

\textbf{Function: \_get\_joint\_position\_inference\_graph(args)}
\begin{itemize}
    \item \textbf{Expected Arguments:}

            \quad\textit{image\_bytes\_feed}

            \quad\textit{batch\_size}

    \item \textbf{Returns:}

            A constructed computation graph that will be used to run human pose
                inference on.

    \item \textbf{Description:}

            The function sets up the computation graph that will decode a JPEG
                from the input \textit{image\_bytes\_feed} in order to pad and
                resize the image to the desired shape. Which is then used to
                run the human pose inference on it using the ``Two VGG-16s
                cascade'' model.
\end{itemize}

\textbf{Function: run()}
\begin{itemize}
    \item \textbf{Expected Arguments:}

    \item \textbf{Returns:}

    \item \textbf{Description:}

            Starts the server in order to handle the HTTP request by listening
                on an SSL-wrapped socket at port 8765 of the localhost. On
                start-up a joint inference computation graph is setup, all
                model weights are restored and a session where the graph can be
                run is initialized.

\end{itemize}

\section{human\_pose\_model - Training and Inference Software Suite}

\subsection{train}

This sub-module of \verb|human_pose_model| does human pose inference model
training.

\textbf{Function: train()}

\begin{itemize}
        \item \textbf{Expected Arguments:} None.

        \item \textbf{Returns:} None.

        \item \textbf{Description:} Trains a human pose estimation network to
                detect and/or regress binary maps and/or confidence maps of
                joint co-ordinates (\verb|NUM_JOINTS| sets of $(x, y)$ co-ordinates).

                Here we only take files $0-N$.  For now files are manually renamed as
                \verb|train[0-N].tfrecord| and \verb|valid[N-M].tfrecord|,
                where there are $N + 1$ train records, $(M - N)$ validation
                records and M + 1 records in total.
\end{itemize}

\subsection{networks}

The \verb|networks| sub-module contains a sub-module called \verb|inference|,
which contains all of the human pose inference model imports, various loss
functions as well as a function to do inference. Besides \verb|inference|, the
\verb|networks| sub-module also contains model definitions themselves (e.g.
\verb|vgg_bulat| for the VGG-16 model).

\textbf{Function: inference()}

\begin{itemize}
        \item \textbf{Expected Arguments:}

        \textit{images}: Mini-batch of preprocessed examples dequeued from the
                input pipeline.

        \textit{heatmaps}: Confidence maps of ground truth joints.

        \textit{weights}: Weights of heatmaps (tensors of all 1s if joint
                present, all 0s if not present).

        \textit{is\_visible\_weights}: Weights of heatmaps/binary maps, with
                occluded joints zero'ed out.

        \textit{gpu\_index}: Index of GPU calculating the current loss.

        \textit{scope}: Name scope for ops, which is different for each tower
                (tower\_N).

        \item \textbf{Returns:} Tensor giving the total loss (combined loss
                from auxiliary and primary logits, added to regularization
                losses).

        \item \textbf{Description:} Sets up a human pose inference model,
                computes predictions on input images and calculates loss on
                those predictions based on an input dense vector of joint
                location confidence maps and binary maps (the ground truth
                vector).

                TF-slim's \verb|arg_scope| is used to keep variables
                (\verb|slim.model_variable|) in CPU memory. See the training
                procedure block diagram in the TF Inception
                \href{https://github.com/tensorflow/models/tree/master/inception}{README}.
\end{itemize}

\section{Features In Development}

\subsection{TensorFlow}

The Caffe deep learning framework (C++) has already been replaced by
TensorFlow. TensorFlow is a newer framework with more support for developers
compared to Caffe. TensorFlow is a library in Python that can generate dataflow
graphs needed for neural networks and deep learning algorithms.

Thanks to the modularity of the project design, replacing the deep learning
framework has not drastically changed the logic of the web application. The web
application refers to a different kind of executable when processing
an uploaded image (it previously referred to a shared object).

Current development of the TensorFlow backend is focused on training a neural
network from scratch, or re-training a standard network such as VGG-16. The
re-training can use parameters learned by the network on a task with massive
datasets available, such as image classification on ImageNet. Certain layers of
the network can then be re-trained to solve the task at hand, human pose
estimation, taking advantage of the image recognition features learned by the
network on the larger dataset.

The focus of the TensorFlow backend is to improve the existing methods by
experimenting with state of the art results in human pose estimation using a
common framework (that being TensorFlow). Once completed, this code could be
contributed back to the open source community, so that others can also run the
TensorFlow implementation of current human pose estimation research methods.

Optical flow will also be added to the TensorFlow single-frame human pose
estimation, in order to extend those estimations to video. An additional
optical flow layer in the network will use the context information from
adjacent frames to better predict joint positions over time in video, as
compared with concatenating the results of making predictions on many
individual frames.

\subsection{Standalone HTTP Server}

In addition to the ASP.NET website, the idea is to have a dedicated HTTP server
that is separate from the .NET website that can take in HTTP requests and run
the pose estimation algorithm and save the image/video to the database.

The main purpose of this server, which is configured to be optimized for
GPU-based execution of the pose estimation algorithm, is to off-load human pose
inference computations from the MVC web server.

Having a separate site would also prevent the possibility of overloading the
main website with too many long-polling requests. This is a definite
possibility if there are a lot of users and activity.

\chapter{Communication Protocol}

This application uses the HTTPS (HyperText Transfer Protocol Secure) to
communicate between the web interface and the server. HTTP over SSL is used due
to browser requirements of HTTPS in order to use the webcam.

The browser's webcam is needed for development of the human pose estimation
app, which is a simple demo of the Text-to-Motion human pose estimation
technology as suggested by Dr.\ He. The web app demo is currently under
development.

\chapter{Development Details}

\section{Languages of implementation}

\begin{itemize}
    \item \textbf{C\#}: ASP.NET Core MVC Framework
    \item \textbf{Python}: Pose Estimation program based on research paper
    \item \textbf{C}: used to wrap the C++ function so that it can be made into a shared object file that can be called from the web app
    \item \textbf{SQLite}: to store database of images
\end{itemize}

\subsubsection{supporting frameworks/plugins:}

\begin{itemize}
    \item \href{http://getbootstrap.com/}{Bootstrap}
    \item \href{https://jquery.com/}{JQuery JS}
    \item \href{https://datatables.net/}{DataTables JS}
\end{itemize}

\section{Languages of Features in development}

\begin{itemize}
    \item \textbf{Python}: Tensorflow
    \item \textbf{MySQL}: for the database schema described in \textbf{section 3}
\end{itemize}

\section{Software}

\begin{itemize}
    \item \textbf{Tensorflow:} to replace Caffe as the deep learning framework
    \item \textbf{OpenCV}: for image manipulation so that uploaded images can
            be converted into types accepted by Caffe
\end{itemize}

\section{Software - for features in development}

\begin{itemize}
    \item \textbf{Sphinx Search:} indexing tool for SQL databases that can speed up search queries. will be included once the SQL database is up and running
\end{itemize}

\section{Hardware}

\begin{itemize}
    \item \textbf{Ubuntu Server - 16.0.4:} hosts the live website at
            \url{https://brendanduke.ca}.
\end{itemize}

\chapter{Reference Links}

\section{ASP.NET Reference List}

\href{https://docs.microsoft.com/en-us/aspnet/core/mvc/overview}{Reference to ASP.NET}

\href{https://docs.microsoft.com/en-us/aspnet/core/api/microsoft.aspnetcore.http.iformfile}{Reference to IFormFile}

\href{https://docs.microsoft.com/en-us/aspnet/core/mvc/views/razor}{Reference to Razor}

\section{Caffe Reference List}

\href{http://caffe.berkeleyvision.org/doxygen/index.html}{Reference to Caffe}

\href{http://caffe.berkeleyvision.org/doxygen/classcaffe_1_1Blob.html}{Reference to caffe::Blob}

\href{http://caffe.berkeleyvision.org/doxygen/classcaffe_1_1Net.html}{Reference to caffe::Net}

this function is related to caffe so was included in this section:

\href{http://www.boost.org/doc/libs/1_63_0/libs/smart_ptr/shared_ptr.htm}{Reference to boost::shared\_ptr}


\section{OpenCV Reference List}

\href{http://docs.opencv.org/3.1.0/}{Reference to OpenCV}

\href{http://docs.opencv.org/3.1.0/d4/d32/classcv_1_1__InputArray.html}{Reference to cv::InputArray}

\href{http://docs.opencv.org/3.1.0/d3/d63/classcv_1_1Mat.html#details}{Reference to cv::Mat}

\href{http://docs.opencv.org/3.1.0/db/d4e/classcv_1_1Point__.html}{Reference to cv::Point}


\end{document}
