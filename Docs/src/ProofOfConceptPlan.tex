\documentclass[a4paper, 12pt]{article}

\usepackage{cite}
\usepackage{amsmath}
\usepackage{fullpage}
\usepackage{url}
\usepackage{graphicx}
\usepackage{inputenc}
\usepackage{titling}

\date{\today}
\title{Proof of Concept Plan for McMaster Text to Motion Database \\CS 4ZP6} 

\author{Brendan Duke\\
        Andrew Kohnen\\
        Udip Patel\\
        Dave Pitkanen\\
        Jordan Viveiros}

\begin{document}

\maketitle

\section{Risks}
The significant risks of this project are split into three major sections represented by the website, database, and deep learning network. The largest risk to the project is linking the three sections together so that the website can pull information from the database, and the deep learning network can use this information to run pose estimation.
Some significant risks are involved within each of these sections and will be elaborated on below:
\begin{itemize}
    \item The website must use full text search in order to correctly return information that the user searched for.
    \item The database must contain all the required videos and text pairings from larger libraries like Charades.
    \item The deep learning network is going to use Tensorflow and requires the steep learning curve that is associated with deep learning.
    \item Generating the proper test cases to provide proof of correctness is difficult on large databases.
\end{itemize}

\section{Datasets}
{Our primary mode of input data for the program will be uploading an image to the website from the user's computer. If these efforts prove fruitful we will wish to We will be largely using the "Charades" Database in order to act as input for our program.}

\section{Deliverables}
{As a proof of concept demo we will show a working website that will function as a base for running pose estimation. This is to show that the associated risks mentioned above can be overcome and fully worked out as the project matures. To utilize the pose estimation the user will either have to upload an image, or search the database from a subset of the options. The prototype will have two aspects to the demonstration with the addition of a third if full text search if it is implemented on a subset of the given data. The first aspect will be a website that can be seen at the time of writing in Figure 1. Once on the website running the pose estimation will be shown by either searching for an action or uploading a picture and displaying the position of the chin, left and right humerus, left and right radius/ulna, left and right femur, left and right Tibia/Fibula and the spine of the person found within the image. 
}
\section{Performance Metrics}
There are a few key aspects to which we can measure the effectiveness of our proof of concept demonstration:
\begin{itemize}
    \item We would like to run this website from any computer at a resonable speed
    \item We would like the ability to take a variety of image types
    \item We would like the pose search function to reasonably fast 
\end{itemize}

\section{Resources}
\begin{itemize}
    \item Caffe
    \item TensorFlow
    \item FFmpeg
    \item Sphinx 
\end{itemize}

{FIX THIS FOR OUR REFERENCES}
\begin{thebibliography}{9}
\bibitem{latexcompanion} 
Michel Goossens, Frank Mittelbach, and Alexander Samarin. 
\textit{The \LaTeX\ Companion}. 
Addison-Wesley, Reading, Massachusetts, 1993.
 
\bibitem{einstein} 
Albert Einstein. 
\textit{Zur Elektrodynamik bewegter K{\"o}rper}. (German) 
[\textit{On the electrodynamics of moving bodies}]. 
Annalen der Physik, 322(10):891â€“921, 1905.
 
\bibitem{knuthwebsite} 
Knuth: Computers and Typesetting,
\\\texttt{http://www-cs-faculty.stanford.edu/\~{}uno/abcde.html}
\end{thebibliography}
\end{document}
