{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def mpii_read_and_decode_single_example(tfrecord):\n",
    "    '''\n",
    "    args: tfrecord for the mpii dataset\n",
    "    returns: parsed example from the tfrecord\n",
    "    '''\n",
    "    \n",
    "    # first construct a queue containing a list of filenames.\n",
    "    # this lets a user split up there dataset in multiple files to keep\n",
    "    # size down\n",
    "    filename_queue = tf.train.string_input_producer([tfrecord],\n",
    "                                                    num_epochs=None)\n",
    "    \n",
    "    # Unlike the TFRecordWriter, the TFRecordReader is symbolic\n",
    "    reader = tf.TFRecordReader()\n",
    "    \n",
    "    # One can read a single serialized example from a filename\n",
    "    # serialized_example is a Tensor of type string.\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    \n",
    "    # the feature map for the mpii dataset allows us to convert the serialized\n",
    "    # example back to non-serialized values\n",
    "    feature_map = {\n",
    "        'image_jpeg': tf.FixedLenFeature(shape=[], dtype=tf.string),\n",
    "        'joint_indices': tf.VarLenFeature(dtype=tf.int64),\n",
    "        'x_joints': tf.VarLenFeature(dtype=tf.float32),\n",
    "        'y_joints': tf.VarLenFeature(dtype=tf.float32),\n",
    "        'head_size': tf.FixedLenFeature(shape=[], dtype=tf.float32)\n",
    "    }\n",
    "    \n",
    "    # The serialized example is converted back to actual values.\n",
    "    # One needs to describe the format of the objects to be returned\n",
    "    example = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features=feature_map)\n",
    "    # now return the converted data\n",
    "    return example\n",
    "\n",
    "x = mpii_read_and_decode_single_example('data/train0.tfrecord')\n",
    "img_jpeg = x['image_jpeg']\n",
    "img_tensor = tf.image.decode_jpeg(contents=img_jpeg, channels=3)\n",
    "decoded_img = tf.image.convert_image_dtype(image=img_tensor, dtype=tf.float32)\n",
    "reshaped_img = tf.reshape(tensor=decoded_img,shape=[380,380,3])\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "x = sess.run(reshaped_img)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Winter2017]",
   "language": "python",
   "name": "Python [Winter2017]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
